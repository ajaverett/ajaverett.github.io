[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Meet Alan!",
    "section": "",
    "text": "Meet Alan!\n    \n    \n    Data Scientist\n    \n      I'm a data scientist committed to driving impactful results through data, whether in the academic, political, or historical domain. I have a passion for Python, R, data visualization, and statistics/machine learning. \n    \n    View My Resume (PDF)\n\n\n\n\nSome of Alan’s Projects\nOn this portfolio, I share and teach what I learn. To get started, you can check out my most popular content below. You can find me on GitHub and LinkedIn. Feel free to reach out to me via mail or follow my Instagram.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhich meme came first?\n\n\n\nPlotly\n\n\nPython\n\n\nVisualization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1st Place Hackathon (Winter 2023)\n\n\n\nStreamlit\n\n\nPlotly\n\n\nPython\n\n\nVisualization\n\n\nReligion\n\n\nNLP\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1st Place Hackathon (Fall 2023)\n\n\n\nR Shiny\n\n\nPlotly\n\n\nPython\n\n\nVisualization\n\n\nMachine Learning\n\n\nGoogle Cloud\n\n\nPolitics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA county like mine\n\n\n\nPlotly\n\n\nPython\n\n\nVisualization\n\n\nPolitics\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Triangle of Power\n\n\n\nMath\n\n\nLatex\n\n\nNotation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpanish Verb Directory\n\n\n\nSpanish\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Data Science Rosetta Stone\n\n\n\nStreamlit\n\n\nPython\n\n\nR\n\n\nSQL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nState of American Christianity\n\n\n\nR\n\n\nVisualization\n\n\nReligion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/usa_christian/index.html",
    "href": "posts/usa_christian/index.html",
    "title": "State of American Christianity",
    "section": "",
    "text": "The General Social Survey (GSS) is a nationally representative survey of American adults that has been conducted since 1972. The GSS is conducted by the National Opinion Research Center (NORC) at the University of Chicago, and it is widely considered to be one of the most important sources of data on trends in American attitudes, beliefs, and behaviors.\nShow the code\n# df_raw &lt;- readxl::read_excel(\"posts/usa_christian/GSS.xlsx\")\n\ndf_raw &lt;- readxl::read_excel(\"GSS.xlsx\")\nRise of ‘None’\nOne of the key findings of the GSS is that Christianity in the United States is in decline. In the early 1970s, around 90% of Americans identified as Christian, but by 2020, that number had dropped to around 70%. This decline is particularly pronounced among young adults, with only around half of adults under the age of 30 identifying as Christian.\nOne of the main reasons for this decline is the rise of the “Nones” - a term used to describe people who do not identify with any particular religion. The number of Nones in the United States has been steadily increasing over the past few decades, and by 2020, around one in four Americans identified as Nones.\nShow the code\nf = df_raw %&gt;%\n  filter(str_detect(as.character(age), \"^[0-9]+$\")) %&gt;% \n  mutate(year = plyr::round_any(as.numeric(year), 10)) %&gt;% \n  mutate(across(everything(), ~replace(., . %in% c(\"Protestant\",\"Catholic\",\"Orthodox-christian\") , \"Christian\"))) %&gt;%\n  mutate(across(everything(), ~replace(., . %in% c(\"Buddhism\",\"Hinduism\",\"Other eastern religions\",\"Inter-nondenominational\",\"Native american\",\"Other\",\"Muslim/islam\") , \"Other\"))) %&gt;%\n  group_by(year, relig) %&gt;% \n  count() %&gt;%\n  filter(!relig %in% c(\".n:  No answer\", \".d:  Do not Know/Cannot Choose\",\".s:  Skipped on Web\")) %&gt;% \n  group_by(year) %&gt;% \n  mutate(percent = round(n/sum(n),5)) %&gt;% \n  mutate(percent_label = (round(n/sum(n),2))*100) %&gt;% \n  mutate(percent_label = percent_label %&gt;%  as.character() %&gt;% paste0(\"%\")) %&gt;% \n  ggplot(aes(x=as.numeric(year), y = percent, color = relig)) + \n  geom_line(linewidth = 1)+\n  geom_point(size = 3.5) +\n  labs(\n    x = \"Year\",\n    y = \"Percent\",\n    color = \"Religion\",\n    title = \"Percent Religon Over Time\"\n  ) +\n  ggrepel::geom_text_repel(aes(label = percent_label)) +\n  scale_y_continuous(labels = scales::percent) +\n  theme_bw()\n\nf %&gt;% ggplotly()\nNew Christians\nWhile Christianity as a whole is in decline, the decline has not been evenly distributed across different denominations. Catholicism has remained relatively stable, with the proportion of Catholics in the U.S. population staying around 30% since the 1970s. On the other hand, the proportion of Protestants has seen a slight decline, dropping from around 55% in the 1970s to around 45% in 2020.\nOther branches of Christianity, such as Mormonism, Jehovah’s Witnesses, and Eastern Orthodoxy, have seen an increase in recent years. By 2020, these denominations made up around 5% of the U.S. population, a significant increase from their representation in the 1970s.\nShow the code\nchristian_vector &lt;- c('PROTESTANT','CATHOLIC','CHRISTIAN','ORTHODOX-CHRISTIAN') %&gt;% tolower()\n\nf = df_raw %&gt;%\n  filter(str_detect(as.character(age), \"^[0-9]+$\")) %&gt;% \n  mutate(year = plyr::round_any(as.numeric(year), 10)) %&gt;% \n  filter(tolower(relig) %in% christian_vector) %&gt;% \n  mutate(across(everything(), ~replace(., . ==  \"Orthodox-christian\" , \"Christian\"))) %&gt;%\n  mutate(across(everything(), ~replace(., . ==  \"Christian\" , \"Other\"))) %&gt;% \n  group_by(year, relig) %&gt;% \n  count() %&gt;% \n  group_by(year) %&gt;% \n  mutate(percent = round(n/sum(n),5)) %&gt;% \n  mutate(percent_label = (round(n/sum(n),2))*100) %&gt;% \n  mutate(percent_label = percent_label %&gt;%  as.character() %&gt;% paste0(\"%\")) %&gt;% \n  ggplot(aes(x=as.numeric(year), y = percent, color = relig)) + \n  geom_line(linewidth = 1)+\n  geom_point(size = 3.5) +\n  labs(\n    x = \"Year\",\n    y = \"Percent\",\n    color = \"Denomination\",\n    title = \"Percent Christian Denomination Over Time\"\n    ) +\n  ggrepel::geom_text_repel(aes(label = percent_label)) +\n  scale_y_continuous(labels = scales::percent) +\n  theme_bw()\n\nf %&gt;% ggplotly()"
  },
  {
    "objectID": "posts/usa_christian/index.html#strength-of-christians",
    "href": "posts/usa_christian/index.html#strength-of-christians",
    "title": "State of American Christianity",
    "section": "Strength of Christians",
    "text": "Strength of Christians\nAnother aspect of the decline of Christianity in the United States is the weakening of its strength within the population. This can be seen in the decreasing participation in religious practices such as church attendance.\nAccording to the GSS, the proportion of general Christians who do not attend church has increased from 15% in 1970 to 23% in 2020. Additionally, the proportion of Christians who attend church weekly has declined from 41% in 1970 to 36% in 2020. However, the proportion of Christians who attend church either monthly or less frequently has remained relatively stable.\nThis decline in church attendance is particularly pronounced among young Christians. The proportion of young Christians who attend church weekly or more frequently has decreased in all categories, except for the “seldom” category in which young Christians increased from 23% in 1970 to 45% in 2020.\nTechnical Note: This code is using the tidyverse and patchwork library to analyze and create a plot of church attendance among Christians over time. The code first filters the dataframe to only include rows where the “age” column contains numeric values, and then converts the “age” and “year” columns to numeric format. Next, it combines all Christian denominations as a single variable called “Christian”, and then filters to only Christians. The code replaces the several different categories of church attendance to Weekly, Monthly, Yearly, and Seldom. The code then groups and counts how many people in each category and uses “ggplot” to make a visualization.\n\n\nShow the code\nchristian_attend &lt;- df_raw %&gt;%\n  filter(str_detect(as.character(age), \"^[0-9]+$\")) %&gt;% \n  mutate(age = as.numeric(age)) %&gt;% \n  mutate(year = plyr::round_any(as.numeric(year), 10)) %&gt;% \n  mutate(age = plyr::round_any(as.numeric(age), 10)) %&gt;% \n  mutate(across(everything(), ~replace(., . %in% c(\"Protestant\",\"Catholic\",\"Orthodox-christian\") , \"Christian\"))) %&gt;% \n  filter(relig == \"Christian\") %&gt;% \n  filter(!attend %in% c(\".d:  Do not Know/Cannot Choose\",\".s:  Skipped on Web\")) %&gt;%\n  mutate(attend = ifelse(attend %in% c(\"Every week\",\"Nearly every week\",\"Several times a week\"), \"Weekly\", attend),\n         attend = ifelse(attend %in% c(\"2-3 times a month\",\"About once a month\",\"At least monthly\"), \"Monthly\", attend),\n         attend = ifelse(attend %in% c(\"About once or twice a year\",\"Several times a year\"), \"Yearly\", attend),\n         attend = ifelse(attend %in% c(\"Less than once a year\",\"Never\"), \"Seldom\", attend)) %&gt;% \n  group_by(year,attend) %&gt;% \n  count() %&gt;% \n  group_by(year) %&gt;% \n  mutate(attend = factor(attend, levels = c(\"Weekly\", \"Monthly\", \"Yearly\",\"Seldom\"))) %&gt;% \n  mutate(percent = round(n/sum(n),5)) %&gt;% \n  mutate(percent_label = (round(n/sum(n),2))*100) %&gt;% \n  mutate(percent_label = percent_label %&gt;%  as.character() %&gt;% paste0(\"%\")) %&gt;% \n  ggplot(aes(x = year, y = percent, group = attend, color = attend)) + \n  geom_line(linewidth = 1)+\n  geom_point(size = 3.5) +\n  labs(\n    x = \"Year\",\n    y = \"\",\n    color = \"Attendance\",\n    title = \"Church Attendance Among\\nChristians Over Time\"\n    ) +\n  ggrepel::geom_text_repel(aes(label = percent_label)) +\n  theme_bw() + theme(legend.position = 'none')\n  \n\ndf_christian &lt;- df_raw %&gt;%\n  filter(str_detect(as.character(age), \"^[0-9]+$\")) %&gt;% \n  mutate(age = as.numeric(age)) %&gt;% \n  mutate(year = plyr::round_any(as.numeric(year), 10)) %&gt;% \n  mutate(age = plyr::round_any(as.numeric(age), 10)) %&gt;% \n  filter(!attend %in% c(\".d:  Do not Know/Cannot Choose\",\".s:  Skipped on Web\")) %&gt;%\n  mutate(attend = ifelse(attend %in% c(\"Every week\",\"Nearly every week\",\"Several times a week\"), \"Weekly\", attend),\n         attend = ifelse(attend %in% c(\"2-3 times a month\",\"About once a month\",\"At least monthly\"), \"Monthly\", attend),\n         attend = ifelse(attend %in% c(\"About once or twice a year\",\"Several times a year\"), \"Yearly\", attend),\n         attend = ifelse(attend %in% c(\"Less than once a year\",\"Never\"), \"Seldom\", attend)) %&gt;% \n  filter(attend != \".n:  No answer\") %&gt;% \n  mutate(attend = factor(attend, levels = c(\"Weekly\", \"Monthly\", \"Yearly\",\"Seldom\"))) \n\nchristian_attend_youth &lt;- df_christian %&gt;%\n  filter(age %in% c(20,30)) %&gt;% \n  group_by(year,attend) %&gt;% \n  count() %&gt;% \n  group_by(year) %&gt;% \n  mutate(percent = round(n/sum(n),5)) %&gt;% \n  mutate(percent_label = (round(n/sum(n),2))*100) %&gt;% \n  mutate(percent_label = percent_label %&gt;%  as.character() %&gt;% paste0(\"%\")) %&gt;% \n  ggplot(aes(x = year, y = percent, group = attend, color = attend)) + \n  geom_line(linewidth = 1)+\n  geom_point(size = 3.5) +\n  labs(\n    x = \"Year\",\n    y = \"\",\n    color = \"Attendance\",\n    title = \"Church Attendance Among\\nChristian Youth Over Time\"\n    ) +\n  ggrepel::geom_text_repel(aes(label = percent_label)) +\n  theme_bw() + \n  theme(\n    # legend.position = 'bottom',\n    legend.direction = \"vertical\"\n    )\n\n\nchristian_attend + christian_attend_youth & scale_y_continuous(limits = c(.1, .46),labels = scales::percent)\n\n\n\n\n\n\n\n\n\nStrength of Protestants\nWhile overall Christianity in the United States is in decline, the decline has not been evenly distributed across different denominations. In particular, the decline of Protestant Christianity appears to be less pronounced than that of Christianity as a whole.\nWhen it comes to church attendance, the data shows that weekly attendance among Protestants has remained relatively stable. According to the GSS, the proportion of Protestants who attend church weekly has remained around 35% since 1970. Furthermore, the weekly attendance for both general Protestants and young Protestants actually increased slightly.\n\n\nShow the code\nprot_attend &lt;- df_christian %&gt;% \n  filter(relig == \"Protestant\") %&gt;% \n  group_by(year,attend) %&gt;% \n  count() %&gt;% \n  group_by(year) %&gt;% \n  mutate(percent = round(n/sum(n),5)) %&gt;% \n  mutate(percent_label = (round(n/sum(n),2))*100) %&gt;% \n  mutate(percent_label = percent_label %&gt;%  as.character() %&gt;% paste0(\"%\")) %&gt;% \n  ggplot(aes(x = year, y = percent, group = attend, color = attend)) + \n  geom_line(linewidth = 1)+\n  geom_point(size = 3.5) +\n  labs(\n    x = \"Year\",\n    y = \"\",\n    color = \"Attendance\",\n    title = \"Church Attendance Among\\nProtestants Over Time\"\n    ) +\n  ggrepel::geom_text_repel(aes(label = percent_label)) +\n  theme_bw() +  theme(legend.position = 'none')\n\nprot_attend_youth &lt;- df_christian %&gt;%\n  filter(relig == \"Protestant\") %&gt;% \n  filter(age %in% c(20,30)) %&gt;% \n  group_by(year,attend) %&gt;% \n  count() %&gt;% \n  group_by(year) %&gt;% \n  mutate(percent = round(n/sum(n),5)) %&gt;% \n  mutate(percent_label = (round(n/sum(n),2))*100) %&gt;% \n  mutate(percent_label = percent_label %&gt;%  as.character() %&gt;% paste0(\"%\")) %&gt;% \n  ggplot(aes(x = year, y = percent, group = attend, color = attend)) + \n  geom_line(linewidth = 1)+\n  geom_point(size = 3.5) +\n  labs(\n    x = \"Year\",\n    y = \"\",\n    color = \"\",\n    title = \"Church Attendance Among\\nProtestant Youth Over Time\"\n    ) +\n  ggrepel::geom_text_repel(aes(label = percent_label)) +\n  theme_bw() + \n  theme(\n    # legend.position = 'bottom',\n    legend.direction = \"vertical\"\n    )\n\n\n\nprot_attend + prot_attend_youth & scale_y_continuous(limits = c(.1, .42),labels = scales::percent)\n\n\n\n\n\n\n\n\n\nStrength of Catholics\nWhile Christianity as a whole is in decline, the decline has not been evenly distributed across different denominations. Among all Christian denominations, the Catholic Church appears to be the one that has been most affected by the decline in attendance.\nAccording to the GSS, weekly attendance among Catholics has decreased significantly since 1970. Among general Catholics, weekly attendance dropped from 53% to 27% during this time period. Similarly, weekly attendance among Catholic youth has also decreased, declining from 40% in 1970 to 15% in 2020.\nHowever, the decline in attendance has not been limited to weekly attendance. The proportion of Catholics who attend church seldom or less frequently has also increased. Seldom attendance increased from 11% in 1970 to 26% in 2020. Furthermore, the youth seldom attendance doubled from 12% to 24% in 2020.\n\n\nShow the code\ncath_attend &lt;- df_christian %&gt;%\n  filter(relig == \"Catholic\") %&gt;% \n  group_by(year,attend) %&gt;% \n  count() %&gt;% \n  group_by(year) %&gt;% \n  mutate(percent = round(n/sum(n),5)) %&gt;% \n  mutate(percent_label = (round(n/sum(n),2))*100) %&gt;% \n  mutate(percent_label = percent_label %&gt;%  as.character() %&gt;% paste0(\"%\")) %&gt;% \n  ggplot(aes(x = year, y = percent, group = attend, color = attend)) + \n  geom_line(linewidth = 1)+\n  geom_point(size = 3.5) +\n  labs(\n    x = \"Year\",\n    y = \"\",\n    color = \"Attendance\",\n    title = \"Church Attendance Among\\nCatholics Over Time\"\n    ) +\n  ggrepel::geom_text_repel(aes(label = percent_label)) +\n  theme_bw() + theme(legend.position = 'none')\n\ncath_attend_youth &lt;- df_christian %&gt;%\n  filter(relig == \"Catholic\") %&gt;% \n  filter(age %in% c(20,30)) %&gt;% \n  group_by(year,attend) %&gt;% \n  count() %&gt;% \n  group_by(year) %&gt;% \n  mutate(percent = round(n/sum(n),5)) %&gt;% \n  mutate(percent_label = (round(n/sum(n),2))*100) %&gt;% \n  mutate(percent_label = percent_label %&gt;%  as.character() %&gt;% paste0(\"%\")) %&gt;% \n  ggplot(aes(x = year, y = percent, group = attend, color = attend)) + \n  geom_line(linewidth = 1) +\n  geom_point(size = 3.5) +\n  labs(\n    x = \"Year\",\n    y = \"\",\n    color = \"Attendance\",\n    title = \"Church Attendance Among\\nCatholic Youth Over Time\"\n    ) +\n  ggrepel::geom_text_repel(aes(label = percent_label)) +\n  theme_bw() + \n  theme(\n    # legend.position = 'bottom',\n    legend.direction = \"vertical\"\n    )\n  \n\ncath_attend + cath_attend_youth & scale_y_continuous(limits = c(.1, .54),labels = scales::percent)\n\n\n\n\n\n\n\n\n\nCharting the decline\nIn conclusion, this blog post has discussed the decline of Christianity in the United States over the past few decades, as reported by the GSS. The data shows that the proportion of Christians in the U.S. population has dropped from around 90% in the early 1970s to around 70% in 2020.\nThe decline of Christianity is also reflected in the weakening of its strength within the population, as seen in the decreasing participation in religious practices such as church attendance. The proportion of general Christians who do not attend church has increased from 15% in 1970 to 23% in 2020 and the proportion of Christians who attend church weekly has declined from 41% in 1970 to 36% in 2020. However, the proportion of Christians who attend church either monthly or less frequently has remained relatively stable.\nWhen looking at different Christian denominations, the decline of Protestant Christianity appears to be less pronounced than that of Christianity as a whole. The proportion of Protestants who attend church weekly has remained around 35% since 1970, and weekly attendance for both general Protestants and young Protestants actually increased slightly. On the other hand, the Catholic Church appears to be the one that has been most affected by the decline in attendance. Among general Catholics, weekly attendance dropped from 53% to 27% during this time period, and the youth seldom attendance doubled from 12% to 24% in 2020.\nThe term “Chreaster” is defined as such: “A Christian who does not frequently attend church, attending only on the major holidays of Christmas and Easter.” (Wiktionary) Chreasters have been on the increase especially among younger Christians and Catholics.\nWhile this blog post does not try to explain the ‘why’ in this phenomenon, there are several factors that readers can probably think of that have led to this decline. Some of the possible factors include the increasing secularization of American society, the rise of social media and the internet, the growing diversity of American society, the sexual abuse scandals that have plagued the Catholic Church, and the loss of trust and credibility among Catholics."
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html",
    "href": "posts/power_triangle/power_triangle.html",
    "title": "The Triangle of Power",
    "section": "",
    "text": "A post on Math Overflow about the relationship between powers, roots, and logs sparked the birth of a notation to harmonize these seemingly unrelated concepts. Grant Sanderson from 3Blue1Brown further popularized and named this notation as, “The Triangle of Power”"
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html#a-remains-constant",
    "href": "posts/power_triangle/power_triangle.html#a-remains-constant",
    "title": "The Triangle of Power",
    "section": "\\(a\\) remains constant",
    "text": "\\(a\\) remains constant\n\\[\n\\begin{align*}\n&\\text{Properties of Logarithms}\n&\\text{Properties of Exponents}\n\\\\\\\\\n&\n\\log_a(x\\times y) = \\log_a(x) + \\log_b(x)\n&\na^{x + y} = a^x \\times a ^y\n\\\\\\\\\n&\n\\log_a(\\frac{x}{y}) = \\log_a(x) - \\log_b(x)\n&\na^{x - y} = \\frac{a^x}{a^y}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html#b-remains-constant",
    "href": "posts/power_triangle/power_triangle.html#b-remains-constant",
    "title": "The Triangle of Power",
    "section": "\\(b\\) remains constant",
    "text": "\\(b\\) remains constant\n\\[\n\\begin{align*}\n&\\text{Properties of Exponents}\n&\\text{Properties of Roots}\n\\\\\\\\\n&   xy^b = x^b \\times y^b\n&   \\sqrt[b]{x\\times y} = \\sqrt[b]{x} \\times \\sqrt[b]{y}\n\\\\\\\\\n&   \\left(\\frac{x}{y}\\right)^b = \\frac{x^b}{y^b}\n&   \\sqrt[b]{\\frac{x}{y}} = \\frac{\\sqrt[b]{x}}{\\sqrt[b]{y}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html#c-remains-constant",
    "href": "posts/power_triangle/power_triangle.html#c-remains-constant",
    "title": "The Triangle of Power",
    "section": "\\(c\\) remains constant",
    "text": "\\(c\\) remains constant\n\\[\n\\begin{align*}\n&\\text{Properties of Logarithms}\n&\\text{Properties of Roots}\n\\\\\\\\\n&   \\log_{x\\times y}(c) = \\left(\\left(\\log_xc\\right)^{-1} + \\left(\\log_yc\\right)^{-1}\\right)^{-1}\n&   \\sqrt[(x^{-1}+ y^{-1})^{-1}]{c} = \\sqrt[x]{c} \\times \\sqrt[y]{c}\n\\\\\\\\\n&   \\log_{\\frac{x}{y}}(c) = \\left(\\left(\\log_xc\\right)^{-1} - \\left(\\log_yc\\right)^{-1}\\right)^{-1}\n&   \\sqrt[(x^{-1}- y^{-1})^{-1}]{c} = \\frac{\\sqrt[x]{c}}{\\sqrt[y]{c}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html#a-remains-constant-1",
    "href": "posts/power_triangle/power_triangle.html#a-remains-constant-1",
    "title": "The Triangle of Power",
    "section": "\\(a\\) remains constant",
    "text": "\\(a\\) remains constant\n\\[\n\\begin{align*}\n&\\text{Properties of Logarithms}\n&\\text{Properties of Exponents}\n\\\\\\\\\n&\n_{a}\n\\stackrel{\\phantom{b}}\n\\triangle _{xy}\n={}\n_{a}\\stackrel{\\phantom{b}}\\triangle _{x} +{}\n_{a}\\stackrel{\\phantom{b}}\\triangle _{y}\n&\n_{a}\n\\stackrel{x+y}\n\\triangle _{\\phantom{c}}\n={}\n_{a}\\stackrel{x}\\triangle _{\\phantom{c}} \\times{}\n_{a}\\stackrel{y}\\triangle _{\\phantom{c}}\n\\\\\\\\\n&_{a}\n\\stackrel{\\phantom{b}}\n\\triangle _{\\frac{x}{y}}\n={}\n_{a}\\stackrel{\\phantom{b}}\\triangle _{x} -{}\n_{a}\\stackrel{\\phantom{b}}\\triangle _{y}\n&\n_{a}\n\\stackrel{x-y}\n\\triangle _{\\phantom{c}}\n={}\n\\frac\n{_{a}\\stackrel{x}\\triangle _{\\phantom{c}}}\n{_{a}\\stackrel{y}\\triangle _{\\phantom{c}}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html#b-remains-constant-1",
    "href": "posts/power_triangle/power_triangle.html#b-remains-constant-1",
    "title": "The Triangle of Power",
    "section": "\\(b\\) remains constant",
    "text": "\\(b\\) remains constant\n\\[\n\\begin{align*}\n&\\text{Properties of Exponents}\n&\\text{Properties of Roots}\n\\\\\\\\\n&\n_{x\\times y}\n\\stackrel{b}\n\\triangle _{\\phantom{c}}\n={}\n_{x}\\stackrel{b}\\triangle _{} \\times{}\n_{y}\\stackrel{b}\\triangle _{}\n&\n_{\\phantom{a}}\n\\stackrel{b}\n\\triangle _{x\\times y}\n={}\n_{\\phantom{x}}\\stackrel{b}\\triangle _{x} \\times{}\n_{\\phantom{x}}\\stackrel{b}\\triangle _{y}\n\\\\\\\\\n&_{\\frac{x}{y}}\n\\stackrel{b}\n\\triangle _{\\phantom{c}}\n={}\n\\frac\n{_{x}\\stackrel{b}\\triangle _{\\phantom{c}} }\n{_{y}\\stackrel{b}\\triangle _{\\phantom{c}} }\n&\n_{\\phantom{a}}\n\\stackrel{b}\n\\triangle _{\\frac{x}{y}}\n=\n\\frac\n{_{\\phantom{a}}\\stackrel{b}\\triangle _{x}}\n{_{\\phantom{a}}\\stackrel{b}\\triangle _{y}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html#c-remains-constant-1",
    "href": "posts/power_triangle/power_triangle.html#c-remains-constant-1",
    "title": "The Triangle of Power",
    "section": "\\(c\\) remains constant",
    "text": "\\(c\\) remains constant\n\\[\n\\begin{align*}\n&\\text{Properties of Logarithms}\n&\\text{Properties of Roots}\n\\\\\\\\\n&\n_{x\\times y}\n\\stackrel{\\phantom{b}}\n\\triangle _{c}\n={}\n\\left(\n\\left( _{x}\\stackrel{}\\triangle _{c}\\right)^{-1} +{}\n\\left(_{y}\\stackrel{}\\triangle _{c}\\right)^{-1}\n\\right)^{-1}\n&\n_{\\phantom{a}}\n\\stackrel{\n  \\left(x^{-1}+y^{-1}\\right)^{-1}\n}\n\\triangle _{c}\n={}\n_{\\phantom{x}}\\stackrel{x}\\triangle _{c} \\times{}\n_{\\phantom{x}}\\stackrel{y}\\triangle _{c}\n\\\\\\\\\n&\n_{\\frac{x}{y}}\n\\stackrel{\\phantom{b}}\n\\triangle _{c}\n={}\n\\left(\n\\left( _{x}\\stackrel{}\\triangle _{c}\\right)^{-1} -{}\n\\left(_{y}\\stackrel{}\\triangle _{c}\\right)^{-1}\n\\right)^{-1}\n&\n_{\\phantom{a}}\n\\stackrel{\n  \\left(x^{-1}-y^{-1}\\right)^{-1}\n}\n\\triangle _{c}\n={}\n\\frac\n{_{\\phantom{x}}\\stackrel{x}\\triangle _{c} }\n{_{\\phantom{x}}\\stackrel{y}\\triangle _{c}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/hack2/index.html",
    "href": "posts/hack2/index.html",
    "title": "1st Place Hackathon (Fall 2023)",
    "section": "",
    "text": "Grassroots campaigns, donation drives, and voter canvassing always start with a voter list. Obtaining these lists is often difficult, and large corporations often monopolize the voter records and sell them to other organizations. We’ve organized the Ohio voting history for 8 million voters across 20 years and combined geographical information with census data, to help political groups find potential voters.\nThe Challenge and Solution\nThe challenge was to create an interface that would allow any grassroots campaign the tools to best allocate their funds to route their outreach program in Ohio My team was able to deliver a website that gives political information inferred from the Ohio voterfile. We used a variety of tools to accomplish this, including:\nPackages Used:\nQuarto, Pandas, Scikit-Learn, Numpy, Plotly, R Shiny, Google Cloud… plus a few others\nThe Result\n\nBelow is the website (click the picture)\n\n    \n        \n    \n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/brainrot/main.html",
    "href": "posts/brainrot/main.html",
    "title": "Which meme came first?",
    "section": "",
    "text": "What the Sigma?\nSeveral neologisms have recently entered into the vocabulary of younger generations. Because of the rapid pace of change in language, it is difficult to determine when these terms first appeared in the broader culture. To investigate this, we can analyze the relative search volume on Google for these terms over time. By identifying the period with the largest increase in search interest, we can determine when each term gained popularity, and which term entered the broader culture first.\nIn order to do this, I downloaded over a hundred CSV files from Google Trends, each containing the relative search volume for a different term. The data spans from January 2010 to the present (September 2024). The data is cleaned and loaded into a pandas DataFrame, and the period with the largest increase in search interest is identified for each term. The relative search volume for each term is then plotted over time, sorted from most to least recent, with a vertical line indicating the period with the largest increase in search interest.\n\n\nFinding the biggest spike!\nLet’s say we want to find the date of the largest increase, \\(t_{max}\\) for any given term. Let \\(y_t\\) represent the search interest value for a given term at time \\(t\\), where \\(t\\) corresponds to any month between January 2010 and the present (September 2024). The change in search interest from one month to the next, \\(\\Delta y_t\\), is computed as the first difference of the time series:\n\\[\n\\Delta y_t = y_t - y_{t-1}\n\\]\nTo capture a broader trend in the changes over time, a rolling sum \\(S\\) is calculated over a window of \\(w\\) months. The rolling sum at a given time \\(t\\) is expressed as:\n\\[\nS_t^{(w)} = \\sum_{i=0}^{w-1} \\Delta y_{t-i}\n\\]\nFor example, when \\(w = 3\\), the rolling sum at time \\(t\\) is calculated as:\n\\[\nS_t^{(3)} = \\Delta y_t + \\Delta y_{t-1} + \\Delta y_{t-2}\n\\]\nThe rolling sum reaches its maximum value at \\(t_{\\text{max}}\\), meaning that this is the period with the largest cumulative increase in search interest:\n\\[\nt_{\\text{max}} = \\arg\\max_t \\left( S_t^{(w)} \\right)\n\\]\nBy comparing \\(t_{\\text{max}}\\) across different terms, we can see which terms like “Sigma” or “Rizz” entered into the broader culture first\n\n\nPlots for all Zalpha neologisms\n\n\nCode\nimport os\nimport pandas as pd\nimport datetime\nimport plotly.express as px\nimport numpy as np\nfrom scipy.signal import find_peaks\n\ndata_folder = 'data'\n\ndef extract_term(file_path):\n    with open(file_path, 'r') as file:\n        file.readline()\n        file.readline()\n        second_line = file.readline()\n        term = second_line.split(',')[1].split(':')[0].strip()\n        return term\n\ndef clean_and_load_data(file_path):\n    df = pd.read_csv(file_path, skiprows=2)\\\n            .set_axis(['date', \"value\"], axis=1)\\\n            .assign(value = lambda x: x['value'].replace('&lt;1', '0.5'))\\\n            .assign(value = lambda x: pd.to_numeric(x['value'], errors='coerce'))\\\n            .assign(date = lambda x: pd.to_datetime(x['date'], format='%Y-%m'))\n    return df\n\ndef find_large_increase_periods(\n    df, \n    value=\"value\", \n    window=3, \n    start_date=\"2010-01-01\"):\n\n    return df\\\n        .query('date &gt; @start_date')\\\n        .assign(diff=lambda x: x[value].diff(1))\\\n        .assign(rolling_diff_sum=lambda x: x['diff']\\\n                .rolling(window=window, min_periods=1)\\\n                .sum())\\\n        .query('rolling_diff_sum == rolling_diff_sum.max()')\\\n        .filter(items=['date'])\\\n        .values[0][0]\n\ndef create_plots(data_dict, sorted_date_dict):\n    plots = []\n    for term in sorted_date_dict.keys():\n        df = data_dict[term].query(\"date &gt; '2010-01-01'\")\n        large_increase_date = sorted_date_dict[term]\n\n        fig = px.line(df, \n            x='date', \n            y='value', \n            title=f'\"{term.title()}\" Relative Search Volume on Google',\n            height=200,\n            labels={\n                \"date\": \"&lt;br&gt;&lt;br&gt;&lt;br&gt;\",\n                \"value\": \"Interest\"})\n\n        fig.add_vline(\n            x=int(large_increase_date) / 1e6,\n            annotation_text=\"Largest Increase\",\n            annotation_position=\"top left\",\n            line=dict(color=\"red\") \n        )\n\n        plots.append(fig)\n    return plots\n\ndata_dict = {}\ndate_dict = {}\n\nfor file in os.listdir(data_folder):\n    if file.endswith('.csv'):\n        file_path = os.path.join(data_folder, file)\n        term = extract_term(file_path)\n        df = clean_and_load_data(file_path) \n        data_dict[term] = df  \n        date_dict[term] = find_large_increase_periods(df)\n\nsorted_date_dict = dict(sorted(date_dict.items(), key=lambda item: item[1], reverse=True))\nplots = create_plots(data_dict, sorted_date_dict)\n\nfor fig in plots:\n    fig.show()\n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Alan's Journey",
    "section": "",
    "text": "Alan's Journey\n\n\n\n\n    \n\n        \n\n        Head of the Hanyang Koo Clan\n\n        \n\n        \n            Alan was born to the name \"구민섭\" (Koo, Min Sub) in South Korea. \n            \n            For the first year of his life, he was raised in the Korean foster care system. He was one of the last kids at the adoption center to get a home!\n\n            According to the Korean Family Registry, he is the head of the Hanyang Koo Clan in South Korea (since he is the only member)\n            \n        \n\n        \n\n    \n\n\n\n\n\n\n\n\n    \n\n        \n\n        Adopted to America\n\n        \n\n        \n            The Averett's adopted Alan and brought him to Phoenix Arizona in the United States. He became the youngest of 5 children. \n            \n            His mother's family was from California and Mexico and his father's family from Wyoming. \n            \n            Throughout his life, his mother worked in education and his father worked in sales with companies across India and Asia.\n        \n        \n\n        \n\n\n    \n\n\n\n\n\n\n\n\n\n    \n    \n\n        \n\n        Eagle Scout in Texas\n\n        \n\n        \n            While Alan was growing up in Texas, he joined the Boy Scouts of America, serving as the Scribe in his troop. In 2018, he earned the rank of Eagle Scout.\n\n            His Eagle Scout project was to run community service events partering with the Pajama Program for disadvantaged youth in the local Austin area. \n            \n        \n\n        \n\n    \n\n    \n\n    \n    \n\n        \n\n        Music in the Marching Band\n\n        \n\n        \n            Even though Alan was the only child not to take piano lessons, that did not stop him from pursuing piano. Alan learned piano by ear and learned from mimicking YouTube videos.   \n\n            In highschool, he was involved in the marching band, learning how to play the keyboard, battery, and auxiliary percussion. He was also involved in chorus as a tenor and bass, singing for the varsity choir.\n\n            Alan joined a band where he played the drumset and keyboard, though it was pretty short-lived.\n\n        \n\n        \n\n\n    \n\n    \n\n    \n    \n\n        \n\n        Competing in the Business Club \n\n        \n\n        \n            Alan, along with his friends, joined and competed in his school's business club, called DECA. He helped run a public relations campaign, partnering with TerraCycle, an innovative recycling company that has become a global leader in recycling hard-to-recycle materials.\n\n            They won regional, state, and went on to compete at the international level in Atlanta, Georgia.\n\n        \n\n        \n\n\n    \n\n    \n\n    \n    \n\n        \n\n        Taekwondo to Tire Repair\n\n        \n\n        \n            Alan has always been eager to work from a young age. In Texas, he took on a variety of jobs- working at a bakery, instructing at a martial arts studio, and fixing tires as a tire repair technician. \n\n        \n\n        \n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n        \n\n        Volunteer work in Maryland\n\n        \n\n        \n\n            After Alan graduated, he spent a year volunteering full-time for his Church as split between a technology consultant, and a volunteer in the humanitarian aid program helping those in the clergy and congregation better use technology for outreach and communication and helping those in need.\n            \n            During this time, he learned how to effectively communicate with others, work in a team, and solve problems. He also improved his Spanish to speak fluently.\n            \n        \n\n        \n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n        \n\n        Data Science and Statistics\n\n        \n\n        \n            When Alan entered university, he ultimately decided to study data science since it combined his interests in statistics, and computer programming. \n\n            During his studies, he was involved in the Data Science Society where he served as President. He was a TA for five courses in the Mathematics Department and ran the data science lab where he trained tutors and helped students with their data science projects.\n            \n            He even won a few hackathons!\n            \n        \n\n        \n\n\n    \n\n    \n\n        \n    \n\n        \n\n        Hispanic Scholarship \n\n        \n\n        \n            During university, Alan was a founding member of SHPE, the Society of Hispanic Professional Engineers. Though not a typical Hispanic person, since he had Hispanic heritage from his mother, he could better relate to the Hispanic experience and community.\n\n            He was awarded the SHPE BYUI National Convention Scholarship from Si Se Puede Scholarship Foundation on top of being a full Pell Grant recipient.\n\n        \n\n        \n\n\n    \n\n    \n\n\n\n\n\n\n\n\n\n    \n\n        \n\n        Pollster in DC\n\n        \n\n        \n            A pollster in Washington DC hired Alan as a Data Science Intern. He worked right on Capitol Hill to help garner information about the 2022 midterm elections. He analyzed voter data trends, applying them to machine learning models.\n            \n        \n\n        \n\n\n    \n\n    \n\n        \n    \n\n        \n\n        Visiting Fellow at the Youth in Policy Institute \n\n        \n\n        \n            Unrelated to his work as a pollster, Alan is also a Visiting Fellow at the Youth in Policy Institute. He worked with a team of youth and young adults to research and write policy papers on issues affecting youth in the United States.\n\n        \n\n        \n\n    \n\n    \n\n\n\n\n\n\n\n\n    \n\n        \n\n        The Best Decision of His Life\n\n        \n\n        \n\n            Alan met Audrey Mae in the same data engineering class. After some skateboard dates and boba, Alan knew she was the one. Alan proposed to Audrey in Tokyo Japan, and they were married in a court house in Salt Lake City, Utah. \n\n            Audrey Mae happened to be a better data scientist and data engineer than Alan, working as a data engineer for a health data company in Utah.\n            \n        \n\n        \n\n    \n    \n\n    \n        \n\n        \n\n    \n\n    \n\n\n\n\n\n\n\n\n\n    \n\n        \n\n        Finally, a Full-Time Job\n\n        \n\n        \n\n            Alan was hired as a Data Scientist at Booz Allen Hamilton in Norfolk, Virginia. He was able to help the Navy gauge readiness for Nuclear-powered Aircraft Carriers.\n            \n        \n\n        \n\n\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/hack1/index.html",
    "href": "posts/hack1/index.html",
    "title": "1st Place Hackathon (Winter 2023)",
    "section": "",
    "text": "The Wilford Woodruff Papers is a collection of documents from the life of Wilford Woodruff, the fourth president of the Mormon Church. The collection contains over 100,000 documents, including journals, letters, and other documents.\nThe Challenge and Solution\nThe challenge was to create a tool that would match the entire corpus of Mormon scripture to the Wilford Woodruff Papers.\nMy team was able to deliver an interactive web application that cross-referenced religious texts with 19th century published journal entries by using a Bag-of-Words model to vectorize n-grams to find textual matches sorted by confidence\nPackages Used:\nStreamlit, Pandas, NLTK, Scikit-Learn, Numpy, Plotly… plus a few others\nThe Result\n\n\n\n    \n        \n    \n\n\nPlay with the app below!\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/pca/pca.html",
    "href": "posts/pca/pca.html",
    "title": "A county like mine",
    "section": "",
    "text": "Principal Component Analysis (PCA) is a statistical technique used to simplify complex data by reducing the number of variables while retaining most of the original information. In other words, it helps to identify the most important patterns or relationships in large datasets by transforming them into a set of linearly uncorrelated variables, known as principal components.\nPCA works by identifying the underlying structure of the data and extracting the directions of maximum variance, which are the principal components. Each principal component is a linear combination of the original variables, and they are orthogonal to each other, meaning that they are uncorrelated. The first principal component captures the most significant variation in the data, and subsequent components capture decreasing amounts of variation. By selecting the appropriate number of principal components, we can reduce the dimensionality of the dataset while retaining the essential information.\nIn this data science project, I used Principal Component Analysis (PCA) to visualize and explore the similarity of various counties in the United States based on a set of demographic metrics including th following:\nThe primary utility of using PCA in this context is to reduce the dimensionality of the dataset while retaining as much information as possible. By doing so, we can efficiently examine patterns and relationships among counties in a lower-dimensional space.\nFor each of these data, I applied PCA to transform the original high-dimensional data into a lower-dimensional space that still captures most of the variation present in the original dataset.\nBy plotting the first two or three principal components on a 2D scatter plot, we can visualize the relationships among counties based on their transformed coordinates. This allows us to identify clusters of similar counties, outliers, or any other interesting patterns. In the code, I also highlighted a specific county (represented by highlighted_area), making it easier to identify its position relative to other counties in the reduced-dimensional space.\nAdditionally, I created a bar chart displaying the proportion of variance explained by each principal component, which helps to determine the optimal number of components to retain for further analysis or modeling.\nThe use of PCA in this project allows us to effectively summarize the complex, high-dimensional relationships between counties, making it easier to identify patterns and interpret the data.\nCode\n# Import\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport plotly.express as px\nimport plotly.graph_objects as go"
  },
  {
    "objectID": "posts/pca/pca.html#pc1",
    "href": "posts/pca/pca.html#pc1",
    "title": "A county like mine",
    "section": "PC1",
    "text": "PC1\nThe first principal component seems to be some measure of traditional metrics of the society including how White the population is, both religious and nonreligious organizations, low criminality, and percent married.\n\n\nCode\nPC1\n\n\nwhite                                      0.184024\nnon_religious_and_religious_orgs_per_1k    0.183871\ncrime_rate_per_100k                       -0.180371\npct_women_married                          0.179891\nnon_religious_non_profit_orgs_per_1k       0.176724\nName: PC1, dtype: float64"
  },
  {
    "objectID": "posts/pca/pca.html#pc2",
    "href": "posts/pca/pca.html#pc2",
    "title": "A county like mine",
    "section": "PC2",
    "text": "PC2\nThe second principal component seems to be some measure of how economically disadvantaged the population is, with measures like poverty rate highly correlated and median household income negatively correlated. Interestingly, religious congregations and teen births per 1k is also highly correlated with this principal component. It seems like this principal component has some aspects of traditionality of the society, but the negative aspects of it.\n\n\nCode\nPC2\n\n\npct_pov017_2020                   0.263468\npct_povall_2020                   0.248170\nmedhhinc_2020                    -0.244717\nreligious_congregations_per_1k    0.225318\npct_bachelors_plus_2017_21       -0.219958\nName: PC2, dtype: float64"
  },
  {
    "objectID": "posts/pca/pca.html#pc3",
    "href": "posts/pca/pca.html#pc3",
    "title": "A county like mine",
    "section": "PC3",
    "text": "PC3\nThe third principal component seems to be some measure of how busy the area is. It is highly correlated with the percent of the population that is employed in the management, production, and construction industry.\n\n\nCode\nPC3\n\n\nciv_labor_force_2021    0.292500\nemployed_2021           0.286014\nmgmt                    0.273708\nproduction              0.263062\nconstruction            0.256393\nName: PC3, dtype: float64"
  },
  {
    "objectID": "posts/pca/pca.html#pc4",
    "href": "posts/pca/pca.html#pc4",
    "title": "A county like mine",
    "section": "PC4",
    "text": "PC4\nThe fourth principal component seems to be some negative measure of civic engagement and social capital.\n\n\nCode\nPC4\n\n\nnon_religious_non_profit_orgs_per_1k       0.296876\nnon_religious_and_religious_orgs_per_1k    0.272233\nrep16_frac                                -0.237853\nrecreation_leisure_est_per_1k              0.234750\nmembership_orgs_per_1k                     0.227421\nName: PC4, dtype: float64"
  },
  {
    "objectID": "posts/pca/pca.html#pc5",
    "href": "posts/pca/pca.html#pc5",
    "title": "A county like mine",
    "section": "PC5",
    "text": "PC5\nNot exactly sure what this principal component is measuring.\n\n\nCode\nPC5\n\n\nhispanic                                                        0.302891\ntwo_or_more                                                     0.263537\nother_race                                                      0.250530\ncharitable_contributions_share_of_agi_middle_class_itemizers   -0.214137\nassociations_per_1k_penn_state_method                          -0.207575\nName: PC5, dtype: float64"
  },
  {
    "objectID": "posts/pca/pca.html#pc6",
    "href": "posts/pca/pca.html#pc6",
    "title": "A county like mine",
    "section": "PC6",
    "text": "PC6\nProbably measures a variable related to something with race and crime\n\n\nCode\nPC6\n\n\ncrime_rate_per_100k    0.253964\nhispanic               0.253551\nag_assault             0.252535\nrape                   0.248669\nblack                 -0.237223\nName: PC6, dtype: float64"
  },
  {
    "objectID": "posts/tutor/index.html",
    "href": "posts/tutor/index.html",
    "title": "The Data Science Rosetta Stone",
    "section": "",
    "text": "The Data Science Rosetta Stone is named after the, a stele inscribed with the same text in three different languages- Ancient Egyptian hieroglyphs, Demotic script, and Ancient Greek. Just like the original Rosetta Stone was used to decipher Egyptian hieroglyphs, the Data Science Rosetta Stone is meant to help you decipher the code of different data science programming languages.\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Alan J Averett",
    "section": "",
    "text": "Certifications: Web and Computer Programming (3.7/4.0); Machine Learning (4.0/4.0)\nLeadership and Awards: Data Science Society President, SHPE Founding Member, Winner of 3 School-wide Hackathons\n\n\nImplemented end-to-end with , ingesting and transforming readiness reports for Nuclear-Powered Aircraft Carriers (CVNs), enabling data-driven insights and visualization on interactive dashboards for the CNAL’s Readiness Operation Center, using analytics tools, including ()\nCollaborated within an framework using for contributing to the continuous improvement and efficiency of the data processing pipeline, and ensuring timely delivery of actionable insights for carrier readiness and operability assessments (obtained Secret Clearance)\n\n\nTransformed a manual 5-hour task into a streamlined 10-minute operation by engineering an advanced to automate the detection of unauthorized use of copyrighted software in mobile applications. Utilized for efficient data management and analysis for scanning mobile application stores, downloading and extracting data, and to identify key indicators of copyright infringement for software usage.\nMaintained regular communication with the CEO, providing updates and insights on project progress, and discussing strategic approaches to enhance software development and data analysis processes.\n\n\nEliminated 50+ anomalous entities in client’s global campaign by in-house tuned methods in for over 200k+ submissions of unstructured raw survey data\nDelivered an interactive recommend algorithm with using various tools such as , , and , to produce detailed analytics for my client’s production team, enhancing user engagement\n\n\nAnalyzed and visualized voter data trends using and to create digestible reports for over a hundred political campaigns, employing to predict ideological disposition and turnout\nImproved accuracy and AUC of all future ML models by 1-3% by feature engineering to classify over 100 million voter records into 12 population density granularities using \n\n\nCoordinated all data science activities, managed all data science tutors, and taught various programming and statistics courses including Business Stats, DS Programming, Data Wrangling and Viz., Big Data Programming, and Linear Algebra\n\n\n\nPython: Pandas, PySpark, Jupyter, numpy, sklearn, polars, tensorflow (keras), pytorch, bs4, selenium, spacy, statsmodels \nVisualization libraries: Databricks, Streamlit, ggplot2, matplotlib / seaborn, plotly, altair, Qlik, PowerBI \nOther Technical Skills: R’s tidyverse, Excel, VBA, SQL, Spark SQL, Git/GitHub, Quarto, LaTeX, Regex, Docker, Advana \n\n\n\n\n Back to top"
  }
]