[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Meet Alan!",
    "section": "",
    "text": "Meet Alan!\n    \n    \n    Data Scientist\n    \n      I'm a data scientist committed to driving impactful results through data, whether in the academic, political, or historical domain. I have a passion for Python, R, data visualization, and statistics/machine learning. \n    \n    View My Resume (PDF)\n\n\n\n\nSome of Alan’s Projects\nOn this portfolio, I share and teach what I learn. To get started, you can check out my most popular content below. You can find me on GitHub and LinkedIn. Feel free to reach out to me via mail or follow my Instagram.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDash through the cosmos\n\n\n\nDash\n\n\nPlotly\n\n\nPython\n\n\nVisualization\n\n\nSpace\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1st Place Hackathon (Winter 2023)\n\n\n\nStreamlit\n\n\nPlotly\n\n\nPython\n\n\nVisualization\n\n\nRelgion\n\n\nNLP\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1st Place Hackathon (Fall 2023)\n\n\n\nR Shiny\n\n\nPlotly\n\n\nPython\n\n\nVisualization\n\n\nMachine Learning\n\n\nGoogle Cloud\n\n\nPolitics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA county like mine\n\n\n\nPlotly\n\n\nPython\n\n\nVisualization\n\n\nPolitics\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Triangle of Power\n\n\n\nMath\n\n\nLatex\n\n\nNotation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantile Regression\n\n\n\nMath\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpanish Verb Directory\n\n\n\nSpanish\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Data Science Rosetta Stone\n\n\n\nStreamlit\n\n\nPython\n\n\nR\n\n\nSQL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nState of American Christianity\n\n\n\nR\n\n\nVisualization\n\n\nReligion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/tutor/index.html",
    "href": "posts/tutor/index.html",
    "title": "The Data Science Rosetta Stone",
    "section": "",
    "text": "The Data Science Rosetta Stone is named after the, a stele inscribed with the same text in three different languages- Ancient Egyptian hieroglyphs, Demotic script, and Ancient Greek. Just like the original Rosetta Stone was used to decipher Egyptian hieroglyphs, the Data Science Rosetta Stone is meant to help you decipher the code of different data science programming languages.\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html",
    "href": "posts/power_triangle/power_triangle.html",
    "title": "The Triangle of Power",
    "section": "",
    "text": "A post on Math Overflow about the relationship between powers, roots, and logs sparked the birth of a notation to harmonize these seemingly unrelated concepts. Grant Sanderson from 3Blue1Brown further popularized and named this notation as, “The Triangle of Power”"
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html#a-remains-constant",
    "href": "posts/power_triangle/power_triangle.html#a-remains-constant",
    "title": "The Triangle of Power",
    "section": "\\(a\\) remains constant",
    "text": "\\(a\\) remains constant\n\\[\n\\begin{align*}\n&\\text{Properties of Logarithms}\n&\\text{Properties of Exponents}\n\\\\\\\\\n&\n\\log_a(x\\times y) = \\log_a(x) + \\log_b(x)\n&\na^{x + y} = a^x \\times a ^y\n\\\\\\\\\n&\n\\log_a(\\frac{x}{y}) = \\log_a(x) - \\log_b(x)\n&\na^{x - y} = \\frac{a^x}{a^y}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html#b-remains-constant",
    "href": "posts/power_triangle/power_triangle.html#b-remains-constant",
    "title": "The Triangle of Power",
    "section": "\\(b\\) remains constant",
    "text": "\\(b\\) remains constant\n\\[\n\\begin{align*}\n&\\text{Properties of Exponents}\n&\\text{Properties of Roots}\n\\\\\\\\\n&   xy^b = x^b \\times y^b\n&   \\sqrt[b]{x\\times y} = \\sqrt[b]{x} \\times \\sqrt[b]{y}\n\\\\\\\\\n&   \\left(\\frac{x}{y}\\right)^b = \\frac{x^b}{y^b}\n&   \\sqrt[b]{\\frac{x}{y}} = \\frac{\\sqrt[b]{x}}{\\sqrt[b]{y}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html#c-remains-constant",
    "href": "posts/power_triangle/power_triangle.html#c-remains-constant",
    "title": "The Triangle of Power",
    "section": "\\(c\\) remains constant",
    "text": "\\(c\\) remains constant\n\\[\n\\begin{align*}\n&\\text{Properties of Logarithms}\n&\\text{Properties of Roots}\n\\\\\\\\\n&   \\log_{x\\times y}(c) = \\left(\\left(\\log_xc\\right)^{-1} + \\left(\\log_yc\\right)^{-1}\\right)^{-1}\n&   \\sqrt[(x^{-1}+ y^{-1})^{-1}]{c} = \\sqrt[x]{c} \\times \\sqrt[y]{c}\n\\\\\\\\\n&   \\log_{\\frac{x}{y}}(c) = \\left(\\left(\\log_xc\\right)^{-1} - \\left(\\log_yc\\right)^{-1}\\right)^{-1}\n&   \\sqrt[(x^{-1}- y^{-1})^{-1}]{c} = \\frac{\\sqrt[x]{c}}{\\sqrt[y]{c}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html#a-remains-constant-1",
    "href": "posts/power_triangle/power_triangle.html#a-remains-constant-1",
    "title": "The Triangle of Power",
    "section": "\\(a\\) remains constant",
    "text": "\\(a\\) remains constant\n\\[\n\\begin{align*}\n&\\text{Properties of Logarithms}\n&\\text{Properties of Exponents}\n\\\\\\\\\n&\n_{a}\n\\stackrel{\\phantom{b}}\n\\triangle _{xy}\n={}\n_{a}\\stackrel{\\phantom{b}}\\triangle _{x} +{}\n_{a}\\stackrel{\\phantom{b}}\\triangle _{y}\n&\n_{a}\n\\stackrel{x+y}\n\\triangle _{\\phantom{c}}\n={}\n_{a}\\stackrel{x}\\triangle _{\\phantom{c}} \\times{}\n_{a}\\stackrel{y}\\triangle _{\\phantom{c}}\n\\\\\\\\\n&_{a}\n\\stackrel{\\phantom{b}}\n\\triangle _{\\frac{x}{y}}\n={}\n_{a}\\stackrel{\\phantom{b}}\\triangle _{x} -{}\n_{a}\\stackrel{\\phantom{b}}\\triangle _{y}\n&\n_{a}\n\\stackrel{x-y}\n\\triangle _{\\phantom{c}}\n={}\n\\frac\n{_{a}\\stackrel{x}\\triangle _{\\phantom{c}}}\n{_{a}\\stackrel{y}\\triangle _{\\phantom{c}}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html#b-remains-constant-1",
    "href": "posts/power_triangle/power_triangle.html#b-remains-constant-1",
    "title": "The Triangle of Power",
    "section": "\\(b\\) remains constant",
    "text": "\\(b\\) remains constant\n\\[\n\\begin{align*}\n&\\text{Properties of Exponents}\n&\\text{Properties of Roots}\n\\\\\\\\\n&\n_{x\\times y}\n\\stackrel{b}\n\\triangle _{\\phantom{c}}\n={}\n_{x}\\stackrel{b}\\triangle _{} \\times{}\n_{y}\\stackrel{b}\\triangle _{}\n&\n_{\\phantom{a}}\n\\stackrel{b}\n\\triangle _{x\\times y}\n={}\n_{\\phantom{x}}\\stackrel{b}\\triangle _{x} \\times{}\n_{\\phantom{x}}\\stackrel{b}\\triangle _{y}\n\\\\\\\\\n&_{\\frac{x}{y}}\n\\stackrel{b}\n\\triangle _{\\phantom{c}}\n={}\n\\frac\n{_{x}\\stackrel{b}\\triangle _{\\phantom{c}} }\n{_{y}\\stackrel{b}\\triangle _{\\phantom{c}} }\n&\n_{\\phantom{a}}\n\\stackrel{b}\n\\triangle _{\\frac{x}{y}}\n=\n\\frac\n{_{\\phantom{a}}\\stackrel{b}\\triangle _{x}}\n{_{\\phantom{a}}\\stackrel{b}\\triangle _{y}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/power_triangle/power_triangle.html#c-remains-constant-1",
    "href": "posts/power_triangle/power_triangle.html#c-remains-constant-1",
    "title": "The Triangle of Power",
    "section": "\\(c\\) remains constant",
    "text": "\\(c\\) remains constant\n\\[\n\\begin{align*}\n&\\text{Properties of Logarithms}\n&\\text{Properties of Roots}\n\\\\\\\\\n&\n_{x\\times y}\n\\stackrel{\\phantom{b}}\n\\triangle _{c}\n={}\n\\left(\n\\left( _{x}\\stackrel{}\\triangle _{c}\\right)^{-1} +{}\n\\left(_{y}\\stackrel{}\\triangle _{c}\\right)^{-1}\n\\right)^{-1}\n&\n_{\\phantom{a}}\n\\stackrel{\n  \\left(x^{-1}+y^{-1}\\right)^{-1}\n}\n\\triangle _{c}\n={}\n_{\\phantom{x}}\\stackrel{x}\\triangle _{c} \\times{}\n_{\\phantom{x}}\\stackrel{y}\\triangle _{c}\n\\\\\\\\\n&\n_{\\frac{x}{y}}\n\\stackrel{\\phantom{b}}\n\\triangle _{c}\n={}\n\\left(\n\\left( _{x}\\stackrel{}\\triangle _{c}\\right)^{-1} -{}\n\\left(_{y}\\stackrel{}\\triangle _{c}\\right)^{-1}\n\\right)^{-1}\n&\n_{\\phantom{a}}\n\\stackrel{\n  \\left(x^{-1}-y^{-1}\\right)^{-1}\n}\n\\triangle _{c}\n={}\n\\frac\n{_{\\phantom{x}}\\stackrel{x}\\triangle _{c} }\n{_{\\phantom{x}}\\stackrel{y}\\triangle _{c}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/hack1/index.html",
    "href": "posts/hack1/index.html",
    "title": "1st Place Hackathon (Winter 2023)",
    "section": "",
    "text": "The Wilford Woodruff Papers is a collection of documents from the life of Wilford Woodruff, the fourth president of the Mormon Church. The collection contains over 100,000 documents, including journals, letters, and other documents.\nThe Challenge and Solution\nThe challenge was to create a tool that would match the entire corpus of Mormon scripture to the Wilford Woodruff Papers.\nMy team was able to deliver an interactive web application that cross-referenced religious texts with 19th century published journal entries by using a Bag-of-Words model to vectorize n-grams to find textual matches sorted by confidence\nPackages Used:\nStreamlit, Pandas, NLTK, Scikit-Learn, Numpy, Plotly… plus a few others\nThe Result\n\n\n\n    \n        \n    \n\n\nPlay with the app below!\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Alan's Journey",
    "section": "",
    "text": "Alan's Journey\n\n\n\n\n    \n\n        \n\n        Daejon, Korea\n\n        \n\n        \n            Alan was born to the name \"Min Soeb\" in Daejon, South Korea. For the first year of his life, he was raised in the Korean foster care system. He was one of the last kids at the adoption center to get a home!\n            \n        \n\n        \n\n    \n\n\n\n\n\n\n\n\n    \n\n        \n\n        Phoenix, Arizona\n\n        \n\n        \n            The Averett's adopted Alan and brought him to Phoenix Arizona in the United States. He became the youngest of 5 children. His mother's family was from California and Mexico and his father's family from Wyoming. Throughout his life, his mother worked as an educator and his father worked in sales with companies across India and Asia.\n            \n        \n\n        \n\n\n    \n\n\n\n\n\n\n\n\n\n    \n    \n\n        \n\n        Austin, Texas\n\n        \n\n        \n            Near the end of elementary school, Alan and his family moved to Austin, Texas. This is where he grew up and spent most of his life. He eventually attended Lake Travis Middle and High School.\n\n        \n\n        \n\n    \n\n    \n\n    \n    \n\n        \n            At Lake Travis High School, he was involved in the marching band, varsity choir, DECA International, and theatre.\n\n            During his time in the marching band, he played in the front ensemble as a marimba and vibraphone player. He also played the piano and sang in the varsity choir as a tenor and bass.\n\n            In DECA, he competed in business competitions and won awards at the regional, state and international level.\n\n        \n\n        \n\n\n    \n\n    \n\n    \n    \n\n        \n            Alan was always determined and eager to work from a young age. In Texas, he took on a variety of jobs- working at a bakery, instructing at a martial arts studio, and fixing tires as a tire repair technician. \n\n        \n\n        \n\n\n    \n\n    \n\n    \n    \n\n        \n            Outside of work and school, Alan was involved in his church as a leader for his local youth group. He pursued martial arts- getting to the rank of red belt at an Olympic certified school before leaving to college. He was even a Scribe in his local Boy Scout troop and earned the rank of Eagle Scout.\n\n        \n\n        \n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n        \n\n        Baltimore, Maryland\n\n        \n\n        \n            After Alan graduated, he served as a Technology Consultant in the Maryland Baltimore Mormon Mission.\n\n            During this time, he learned how to effectively communicate with others, work in a team, and solve problems. He also learned how to speak Spanish fluently.\n            \n        \n\n        \n\n\n    \n\n\n\n\n\n\n\n\n\n    \n\n        \n\n        Rexburg, Idaho\n\n        \n\n        \n            When Alan entered in college, he ultimately decided to study data science since it combined his interests in statistics, and computer programming. \n\n            At Brigham Young University- Idaho, he was involved in the Data Science Society where he served as President. He was a TA for five courses in the Mathematics Department and ran the data science lab where he trained tutors and helped students with their data science projects.\n            \n            He even won a few hackathons!\n            \n        \n\n        \n\n\n    \n\n\n\n\n\n\n\n\n    \n\n        \n\n        Washington, DC\n\n        \n\n        \n            A pollster in Washington DC hired Alan as a Data Science Intern. He worked right on capitol hill to help garner information about the 2022 midterm elections. He analyzed voter data trends, applying them to machine learning models.\n            \n        \n\n        \n\n\n    \n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/pca/pca.html",
    "href": "posts/pca/pca.html",
    "title": "A county like mine",
    "section": "",
    "text": "Principal Component Analysis (PCA) is a statistical technique used to simplify complex data by reducing the number of variables while retaining most of the original information. In other words, it helps to identify the most important patterns or relationships in large datasets by transforming them into a set of linearly uncorrelated variables, known as principal components.\nPCA works by identifying the underlying structure of the data and extracting the directions of maximum variance, which are the principal components. Each principal component is a linear combination of the original variables, and they are orthogonal to each other, meaning that they are uncorrelated. The first principal component captures the most significant variation in the data, and subsequent components capture decreasing amounts of variation. By selecting the appropriate number of principal components, we can reduce the dimensionality of the dataset while retaining the essential information.\nIn this data science project, I used Principal Component Analysis (PCA) to visualize and explore the similarity of various counties in the United States based on a set of demographic metrics including th following:\nThe primary utility of using PCA in this context is to reduce the dimensionality of the dataset while retaining as much information as possible. By doing so, we can efficiently examine patterns and relationships among counties in a lower-dimensional space.\nFor each of these data, I applied PCA to transform the original high-dimensional data into a lower-dimensional space that still captures most of the variation present in the original dataset.\nBy plotting the first two or three principal components on a 2D scatter plot, we can visualize the relationships among counties based on their transformed coordinates. This allows us to identify clusters of similar counties, outliers, or any other interesting patterns. In the code, I also highlighted a specific county (represented by highlighted_area), making it easier to identify its position relative to other counties in the reduced-dimensional space.\nAdditionally, I created a bar chart displaying the proportion of variance explained by each principal component, which helps to determine the optimal number of components to retain for further analysis or modeling.\nThe use of PCA in this project allows us to effectively summarize the complex, high-dimensional relationships between counties, making it easier to identify patterns and interpret the data.\nCode\n# Import\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport plotly.express as px\nimport plotly.graph_objects as go"
  },
  {
    "objectID": "posts/pca/pca.html#pc1",
    "href": "posts/pca/pca.html#pc1",
    "title": "A county like mine",
    "section": "PC1",
    "text": "PC1\nThe first principal component seems to be some measure of traditional metrics of the society including how White the population is, both religious and nonreligious organizations, low criminality, and percent married.\n\n\nCode\nPC1\n\n\nwhite                                      0.184024\nnon_religious_and_religious_orgs_per_1k    0.183871\ncrime_rate_per_100k                       -0.180371\npct_women_married                          0.179891\nnon_religious_non_profit_orgs_per_1k       0.176724\nName: PC1, dtype: float64"
  },
  {
    "objectID": "posts/pca/pca.html#pc2",
    "href": "posts/pca/pca.html#pc2",
    "title": "A county like mine",
    "section": "PC2",
    "text": "PC2\nThe second principal component seems to be some measure of how economically disadvantaged the population is, with measures like poverty rate highly correlated and median household income negatively correlated. Interestingly, religious congregations and teen births per 1k is also highly correlated with this principal component. It seems like this principal component has some aspects of traditionality of the society, but the negative aspects of it.\n\n\nCode\nPC2\n\n\npct_pov017_2020                   0.263468\npct_povall_2020                   0.248170\nmedhhinc_2020                    -0.244717\nreligious_congregations_per_1k    0.225318\npct_bachelors_plus_2017_21       -0.219958\nName: PC2, dtype: float64"
  },
  {
    "objectID": "posts/pca/pca.html#pc3",
    "href": "posts/pca/pca.html#pc3",
    "title": "A county like mine",
    "section": "PC3",
    "text": "PC3\nThe third principal component seems to be some measure of how busy the area is. It is highly correlated with the percent of the population that is employed in the management, production, and construction industry.\n\n\nCode\nPC3\n\n\nciv_labor_force_2021    0.292500\nemployed_2021           0.286014\nmgmt                    0.273708\nproduction              0.263062\nconstruction            0.256393\nName: PC3, dtype: float64"
  },
  {
    "objectID": "posts/pca/pca.html#pc4",
    "href": "posts/pca/pca.html#pc4",
    "title": "A county like mine",
    "section": "PC4",
    "text": "PC4\nThe fourth principal component seems to be some negative measure of civic engagement and social capital.\n\n\nCode\nPC4\n\n\nnon_religious_non_profit_orgs_per_1k      -0.296876\nnon_religious_and_religious_orgs_per_1k   -0.272233\nrep16_frac                                 0.237853\nrecreation_leisure_est_per_1k             -0.234750\nmembership_orgs_per_1k                    -0.227421\nName: PC4, dtype: float64"
  },
  {
    "objectID": "posts/pca/pca.html#pc5",
    "href": "posts/pca/pca.html#pc5",
    "title": "A county like mine",
    "section": "PC5",
    "text": "PC5\nNot exactly sure what this principal component is measuring.\n\n\nCode\nPC5\n\n\nhispanic                                                       -0.302891\ntwo_or_more                                                    -0.263537\nother_race                                                     -0.250530\ncharitable_contributions_share_of_agi_middle_class_itemizers    0.214137\nassociations_per_1k_penn_state_method                           0.207575\nName: PC5, dtype: float64"
  },
  {
    "objectID": "posts/pca/pca.html#pc6",
    "href": "posts/pca/pca.html#pc6",
    "title": "A county like mine",
    "section": "PC6",
    "text": "PC6\nProbably measures a variable related to something with race and crime\n\n\nCode\nPC6\n\n\ncrime_rate_per_100k    0.253964\nhispanic               0.253551\nag_assault             0.252535\nrape                   0.248669\nblack                 -0.237223\nName: PC6, dtype: float64"
  },
  {
    "objectID": "posts/qreg/index.html",
    "href": "posts/qreg/index.html",
    "title": "Quantile Regression",
    "section": "",
    "text": "A recap on simple linear Regression\nGiven data with the following assumptions:\n\nLinear Relation: the true regression relation between \\(Y\\) and \\(X\\) is linear.\nNormal Errors: the error terms \\(\\epsilon_i\\) are normally distributed with a mean of zero.\nConstant Variance: the variance \\(\\sigma^2\\) of the error terms is constant over all \\(X_i\\) values.\nFixed \\(X\\): the \\(X_i\\) values can be considered fixed and measured without error.\nIndependent Errors: the error terms \\(\\epsilon_i\\),are independent.\n\nWe can model the data with the following equation:\n\\[\n\\mathbb{E}[Y_i​∣X_i]=\\beta_0​+\\beta_1​X_i​\n\\]\nThe interpretation of thse slope in this model is increase in the average or expected value of \\(Y\\) given a unit change in \\(X\\).\nThe problem with this is that this is limited.\n\n\nQuantile Regression\n\\[\n\\mathbb{Q}_{\\tau}[Y_i∣X_i]=\\beta_0+\\beta_1X_i\n\\]\n\n\nCode\nlibrary(tidyverse)\nlibrary(mosaic)\nlibrary(gridExtra)\nlibrary(plotly)\n\n\n\n\n\nCode\nfig1 = Utilities %&gt;% \n  head(15) %&gt;% \n  ggplot(aes(x = kwh, y= elecbill)) +\n  geom_point(size=5, alpha=.4) +\n  geom_smooth(method=\"lm\", se=F, linewidth=2, color=\"black\") +\n  # geom_quantile(quantiles = 0.5, linewidth=2, color=\"purple\") +\n  theme_classic() +\n  labs(title=\"Without Outlier\")+\n  coord_cartesian(ylim=c(0,100), xlim=c(0,1650))\n\nfig2 = Utilities %&gt;% \n  head(15) %&gt;% \n  bind_rows(data.frame(kwh=1600, elecbill=0)) %&gt;% \n  ggplot(aes(x = kwh, y= elecbill)) +\n  geom_point(size=5, alpha=.4) +\n  geom_smooth(method=\"lm\", se=F, linewidth=2, color=\"black\") +\n  # geom_quantile(quantiles = 0.5, linewidth=2, color=\"purple\") +\n  theme_classic()+\n  labs(title=\"With Outlier\")+\n  coord_cartesian(ylim=c(0,100), xlim=c(0,1650))\n\nsubplot(fig1 %&gt;% ggplotly, fig2 %&gt;% ggplotly) %&gt;% \n  layout(title = 'Regression Estimating the Mean Y')\n\n\n\n\n\n\n\n\n\nCode\nfig1 = Utilities %&gt;% \n  head(15) %&gt;% \n  ggplot(aes(x = kwh, y= elecbill)) +\n  geom_point(size=5, alpha=.4) +\n  # geom_smooth(method=\"lm\", se=F, linewidth=2, color=\"black\") +\n  geom_quantile(quantiles = 0.5, linewidth=2, color=\"purple\") +\n  theme_classic() +\n  labs(title=\"Without Outlier\")+\n  coord_cartesian(ylim=c(0,100), xlim=c(0,1650))\n\nfig2 = Utilities %&gt;% \n  head(15) %&gt;% \n  bind_rows(data.frame(kwh=1600, elecbill=0)) %&gt;% \n  ggplot(aes(x = kwh, y= elecbill)) +\n  geom_point(size=5, alpha=.4) +\n  # geom_smooth(method=\"lm\", se=F, linewidth=2, color=\"black\") +\n  geom_quantile(quantiles = 0.5, linewidth=2, color=\"purple\") +\n  theme_classic()+\n  labs(title=\"With Outlier\")+\n  coord_cartesian(ylim=c(0,100), xlim=c(0,1650))\n\nsubplot(fig1 %&gt;% ggplotly, fig2 %&gt;% ggplotly) %&gt;% \n  layout(title = 'Regression Estimating the Median Y')\n\n\n\n\n\n\n\n\nCode\nlibrary(quantreg)\n\n\nWarning: package 'quantreg' was built under R version 4.2.3\n\n\nLoading required package: SparseM\n\n\n\nAttaching package: 'SparseM'\n\n\nThe following object is masked from 'package:base':\n\n    backsolve\n\n\nCode\ndf = Utilities %&gt;% \n  head(15) %&gt;% \n  bind_rows(data.frame(kwh=1600, elecbill=0)) \n\n# model assumes slopes are the same\navg_reg &lt;- lm(elecbill ~ kwh, data = df)\nmed_reg &lt;- rq(elecbill ~ kwh, data = df, tau = .5)\n\nAIC(avg_reg, med_reg) %&gt;% \n  pander::pander()\n\n\n\n\n\n\n\n\n\n\n \ndf\nAIC\n\n\n\n\navg_reg\n3\n152.5\n\n\nmed_reg\n2\n142.8\n\n\n\n\n\n\n\nCode\nlibrary(sjPlot) \ntheme_set(theme_bw())\nplot_models(avg_reg, med_reg, show.values = TRUE, \n            m.labels = c(\"Linear model\", \"Median model\"), \n            legend.title = \"Model type\")\n\n\nWarning in rq.fit.br(x, y, tau = tau, ci = TRUE, ...): Solution may be nonunique\n\n\nWarning in summary.rq(x, covariance = TRUE): 1 non-positive fis\n\nWarning in summary.rq(x, covariance = TRUE): 1 non-positive fis\n\nWarning in summary.rq(x, covariance = TRUE): 1 non-positive fis\n\n\n\n\n\ncheck out\nhttps://yuzar-blog.netlify.app/posts/2022-12-01-quantileregression/ https://www.youtube.com/watch?v=Gtz8ca_4hVg https://www.youtube.com/watch?v=OQGIdfEHNnQ https://www.jmlr.org/papers/volume7/meinshausen06a/meinshausen06a.pdf https://academic.oup.com/jrsssd/article-abstract/52/3/331/7123575 https://www.sebastianbuhai.com/papers/publications/quantile_regressions.pdf https://support.sas.com/resources/papers/proceedings/proceedings/sugi30/213-30.pdf http://www.econ.uiuc.edu/~roger/research/intro/rq3.pdf https://www2.stat.duke.edu/~fl35/teaching/440-19F/decks/cs01_5_deck.html#/class-exercise-2\n\n\n\n\n Back to top"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Alan J Averett",
    "section": "",
    "text": "Certifications: Web and Computer Programming (3.7/4.0); Machine Learning (4.0/4.0)\nLeadership and Awards: Data Science Society President, SHPE Founding Member, Winner of 3 School-wide Hackathons\n\n\n\nTransformed a manual 5-hour task into a streamlined 10-minute operation by engineering an advanced to automate the detection of unauthorized use of copyrighted software in mobile applications\nUtilized for efficient data management and analysis for scanning mobile application stores, downloading and extracting data, and to identify key indicators of copyright infringement for software usage\n\n\nEliminated 50+ anomalous entities in a worldwide initiative by in-house tuned anomaly detection methods in for over 200k+ submissions of unstructured raw survey data\nFrequently delivered summaries of key findings of statistical analyses to the executive team\n\n\nCreated digestible reports for 80+ political campaigns by analyzing/visualizing voter data trends with machine learning models that predicted ideological disposition and turnout using and \nDecreased production time (1 hr to 1 min) by building an automated script to clean and transform voter data\nIncreased accuracy and AUC for all future machine learning models (~ 1-3 percent) by using data to categorize over 100 million records of voter data into 12 granularities of population density using and other geospatial libraries\n\n\nLed and coordinated data science society activities and meetings; mentored and supported project teams including weekly bootcamps to teach , over 6 teams of ~ 6-12 people each\nManaged, and trained all tutors for school-wide DS Lab, teaching , in \nTutored Business Stats, DS Programming, Data Wrangling and Viz., Big Data Programming, and Linear Algebra courses in to 100+ students \n\n\nProvided actionable graphs and trends using tools including and unsupervised textual clustering alongside as part of the Wilford Woodruff production team in Python\nDelivered an that cross-referenced religious texts with 19th century published journal entries by using a Bag-of-Words model to vectorize n-grams to find textual matches sorted by confidence using \nCreated similarity algorithm by topic to model recommendations to increase user interaction time with company website\n\n\n\nPython: Pandas, NumPy, Sci-kit Learn, PySpark, Polars, Keras / Tensorflow, BeautifulSoup4, DataBricks \nR: CAR, Mosaic, RMarkdown, Tidyverse (dplyr, tidyr, stringr, forcats, lubridate, purrr, etc.) \nVisualization libraries: Streamlit, ggplot2, Matplotlib / Seaborn, Plotly Express, Altair \nOther Technical Skills: Excel, Visual Basic for App. (VBA), SQL, MySQL, Git/GitHub, Quarto, LaTeX, Regex, Docker \n\n\n\n\n Back to top"
  }
]